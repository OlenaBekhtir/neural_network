import numpy as np
#  сигмоидальная функция приведения чисел (sigmoid)
def nonlin(x, seed=False): # превращает целое число в вывод нейросети
    if seed:
        return x * (1 - x)
    return 1 / (1 + np.exp(-x))

# объявляем переменную Х как двумерный массив
x = np.array([[0, 0, 1],
              [0, 1, 1],
              [1, 0, 1],
              [1, 1, 1]]) # в Х запишется транспонированная матрица

# делаем новый массивБ в котором будут выводы, сознательно вводим ошибку в строку вывода для проверки работы нейросети (второй 0)
y = np.array([[0, 1, 1, 1]]).T # T - операция транспонирования, чтобы избежать путаницы при выводе

# расчеты нейросети
# создаем зерно генерации, чтобы сделать функцию детерминированной
np.random.seed(1)
# задаем семантический вес (случайным образом)
syn0 = 2 * np.random.random((3, 1)) - 1 # нулевой сенаптический вес
# узел = иттерации
for iter in range (10000):
    l0 = x # сделаем копию вводного массива х, чтобыфунткция была чистой, то есть с ней можно работать независимо от входного массива
    l1 = nonlin(np.dot(l0, syn0)) # перераспределенные значения входного массиваб к вводному числу приклеили семантический вес, это будет выводной слой
    l1_error = y - l1 # переменная, которая хранит коэффициент ошибки
    l1_delta = l1_error * nonlin(l1, True) # способ конкретизировать ошибку, нелинейный вывод превращаем в линейный
# обновляем семантический вес
    syn0 += np.dot(l0.T, l1_delta)
# вывод результата
print("Вывод после тренировки")
print (l1)
